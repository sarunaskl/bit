{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn from mistakes and refine them for future steps, thereby improving the quality of final </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the model weights (often hard to change after pre-training), including current information, code execution </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">where Thought: … step is removed.\\nReflexion (Shinn &amp; Labash 2023) is a framework to equip agents with dynamic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the reward model provides a simple binary reward and the action space follows the setup in ReAct where the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">&amp; Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">defined as encountering a sequence of consecutive identical actions that lead to the same observation in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn &amp; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">should expect the next predicted action to lead to better performance than previous trials. The goal is to learn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actions. The history data is generated by a set of source policies, each trained for a specific task. At the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trajectories instead of learning history), source policy (used for generating trajectories for distillation by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conditioned on partial training history of the source policy, AD also improves much faster than ED </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">involves skills and routines that are performed automatically, like riding a bike or typing on a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that similar input items are mapped to the same buckets with high probability, where the number of buckets is much </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">space into half and each leaf stores one data point. Trees are built independently and at random, so to some </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for cluster candidates with coarse quantization and then further looks into each cluster with finer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in HuggingFace platform according to the model descriptions and summarize the response based on the execution </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">}}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistant helps the user to select a suitable model from a list of models to process the user request. The AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model inference results to the user in the first person. If inference results contain a file path, must tell the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calculator, calendar queries, smart home control, schedule management, health data management, account </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">description, the model needs to determine whether to call a given API, call it correctly, and respond properly to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guides the agent’s future behavior. They are higher-level summaries of past events (&lt;- note that this is a bit </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning &amp;</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">taken into consideration for planning and reacting.\\nEnvironment information is present in a tree </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">save important information to files.\\n2. If you are unsure how you previously did something or want to recall past </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"&lt;search&gt;\"\\n2. Browse Website: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"browse_website\", args: \"url\": \"&lt;url&gt;\", \"question\": \"&lt;what_you_want_to_find_on_website&gt;\"\\n3. Start GPT Agent: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"start_agent\", args: \"name\": \"&lt;name&gt;\", \"task\": \"&lt;short_task_desc&gt;\", \"prompt\": \"&lt;prompt&gt;\"\\n4. Message GPT Agent: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"message_agent\", args: \"key\": \"&lt;key&gt;\", \"message\": \"&lt;message&gt;\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPT Agent: \"delete_agent\", args: \"key\": \"&lt;key&gt;\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;url&gt;\", \"clone_path\": \"&lt;directory&gt;\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"&lt;file&gt;\", \"text\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;text&gt;\"\\n9. Read file: \"read_file\", args: \"file\": \"&lt;file&gt;\"\\n10. Append to file: \"append_to_file\", args: \"file\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;file&gt;\", \"text\": \"&lt;text&gt;\"\\n11. Delete file: \"delete_file\", args: \"file\": \"&lt;file&gt;\"\\n12. Search Files: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"search_files\", args: \"directory\": \"&lt;directory&gt;\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;full_code_string&gt;\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"&lt;list_of_suggestions&gt;\", \"code\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;full_code_string&gt;\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"&lt;full_code_string&gt;\", \"focus\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;list_of_focus_areas&gt;\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"&lt;file&gt;\"\\n17. Generate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Image: \"generate_image\", args: \"prompt\": \"&lt;prompt&gt;\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"&lt;text&gt;\"\\n19. Do </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;reason&gt;\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n   </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">definition file.\\nBefore you finish, double check that all parts of the architecture is present in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that files contain all imports, types etc. Make sure that code in different files are compatible with each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">file must strictly follow a markdown code block format, where the following tokens must be replaced such </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">restricted context capacity limits the inclusion of historical information, detailed instructions, API call </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context, and responses. The design of the system has to work with this limited communication bandwidth, while </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interface between LLMs and external components such as memory and tools. However, the reliability of model outputs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">= \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn &amp; Labash. “Reflexion: an autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading \u001b[0m\n",
       "\u001b[32mTime: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is\u001b[0m\n",
       "\u001b[32ma cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring \u001b[0m\n",
       "\u001b[32mexamples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it \u001b[0m\n",
       "\u001b[32mcan be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent \u001b[0m\n",
       "\u001b[32msystem, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and \u001b[0m\n",
       "\u001b[32mdecomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of \u001b[0m\n",
       "\u001b[32mcomplex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, \u001b[0m\n",
       "\u001b[32mlearn from mistakes and refine them for future steps, thereby improving the quality of final \u001b[0m\n",
       "\u001b[32mresults.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSee Prompt Engineering\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as\u001b[0m\n",
       "\u001b[32mutilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability \u001b[0m\n",
       "\u001b[32mto retain and recall \u001b[0m\u001b[32m(\u001b[0m\u001b[32minfinite\u001b[0m\u001b[32m)\u001b[0m\u001b[32m information over extended periods, often by leveraging an external vector store and\u001b[0m\n",
       "\u001b[32mfast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from \u001b[0m\n",
       "\u001b[32mthe model weights \u001b[0m\u001b[32m(\u001b[0m\u001b[32moften hard to change after pre-training\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, including current information, code execution \u001b[0m\n",
       "\u001b[32mcapability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered \u001b[0m\n",
       "\u001b[32mautonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs \u001b[0m\n",
       "\u001b[32mto know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a \u001b[0m\n",
       "\u001b[32mstandard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think \u001b[0m\n",
       "\u001b[32mstep by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT \u001b[0m\n",
       "\u001b[32mtransforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking \u001b[0m\n",
       "\u001b[32mprocess.\\nTree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m extends CoT by exploring multiple reasoning possibilities at each \u001b[0m\n",
       "\u001b[32mstep. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, \u001b[0m\n",
       "\u001b[32mcreating a tree structure. The search process can be BFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbreadth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or DFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdepth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[32meach state evaluated by a classifier \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvia a prompt\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or majority vote.\\nTask decomposition can be done \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by LLM \u001b[0m\n",
       "\u001b[32mwith simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by using \u001b[0m\n",
       "\u001b[32mtask-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with human inputs.\\nAnother \u001b[0m\n",
       "\u001b[32mquite distinct approach, LLM+P \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, involves relying on an external classical planner to do \u001b[0m\n",
       "\u001b[32mlong-horizon planning. This approach utilizes the Planning Domain Definition Language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPDDL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as an intermediate \u001b[0m\n",
       "\u001b[32minterface to describe the planning problem. In this process, LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m translates the problem into “Problem PDDL”, \u001b[0m\n",
       "\u001b[32mthen \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mtranslates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external \u001b[0m\n",
       "\u001b[32mtool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic \u001b[0m\n",
       "\u001b[32msetups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous \u001b[0m\n",
       "\u001b[32magents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a \u001b[0m\n",
       "\u001b[32mcrucial role in real-world tasks where trial and error are inevitable.\\nReAct \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m integrates \u001b[0m\n",
       "\u001b[32mreasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions\u001b[0m\n",
       "\u001b[32mand the language space. The former enables LLM to interact with the environment \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. use Wikipedia search API\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mwhile the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template \u001b[0m\n",
       "\u001b[32mincorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: \u001b[0m\n",
       "\u001b[32m...\\n... \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRepeated many times\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. \u001b[0m\n",
       "\u001b[32mHotpotQA, FEVER\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and decision-making tasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. AlfWorld Env, WebShop\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Yao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nIn both \u001b[0m\n",
       "\u001b[32mexperiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline \u001b[0m\n",
       "\u001b[32mwhere Thought: … step is removed.\\nReflexion \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShinn & Labash 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a framework to equip agents with dynamic \u001b[0m\n",
       "\u001b[32mmemory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which \u001b[0m\n",
       "\u001b[32mthe reward model provides a simple binary reward and the action space follows the setup in ReAct where the \u001b[0m\n",
       "\u001b[32mtask-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, \u001b[0m\n",
       "\u001b[32mthe agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial \u001b[0m\n",
       "\u001b[32mdepending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shinn \u001b[0m\n",
       "\u001b[32m& Labash, 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and\u001b[0m\n",
       "\u001b[32mshould be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is\u001b[0m\n",
       "\u001b[32mdefined as encountering a sequence of consecutive identical actions that lead to the same observation in the \u001b[0m\n",
       "\u001b[32menvironment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfailed \u001b[0m\n",
       "\u001b[32mtrajectory, ideal reflection for guiding future changes in the plan\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Then reflections are added into the agent’s \u001b[0m\n",
       "\u001b[32mworking memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and \u001b[0m\n",
       "\u001b[32mHotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shinn & \u001b[0m\n",
       "\u001b[32mLabash, 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nChain of Hindsight \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoH; Liu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m encourages the model to improve on its own outputs by \u001b[0m\n",
       "\u001b[32mexplicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a \u001b[0m\n",
       "\u001b[32mcollection of $D_h = \\\\\u001b[0m\u001b[32m{\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx, y_i , r_i , z_i\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^n$, where $x$ is the prompt, each $y_i$ is a model \u001b[0m\n",
       "\u001b[32mcompletion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. \u001b[0m\n",
       "\u001b[32mAssume the feedback tuples are ranked by reward, $r_n \\\\geq r_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mn-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\geq \\\\dots \\\\geq r_1$ The process is \u001b[0m\n",
       "\u001b[32msupervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx, z_i, y_i, z_j, y_j, \\\\dots, z_n, \u001b[0m\n",
       "\u001b[32my_n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the \u001b[0m\n",
       "\u001b[32msequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The \u001b[0m\n",
       "\u001b[32mmodel can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid \u001b[0m\n",
       "\u001b[32moverfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid \u001b[0m\n",
       "\u001b[32mshortcutting and copying \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbecause there are many common words in feedback sequences\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, they randomly mask 0% - 5% of\u001b[0m\n",
       "\u001b[32mpast tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, \u001b[0m\n",
       "\u001b[32msummarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model \u001b[0m\n",
       "\u001b[32mcan follow instructions to produce outputs with incremental improvement in a sequence. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Liu et al. \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to \u001b[0m\n",
       "\u001b[32mtake on the trend to produce better outputs. Algorithm Distillation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAD; Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m applies the same idea \u001b[0m\n",
       "\u001b[32mto cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long \u001b[0m\n",
       "\u001b[32mhistory-conditioned policy. Considering that an agent interacts with the environment many times and in each episode\u001b[0m\n",
       "\u001b[32mthe agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we \u001b[0m\n",
       "\u001b[32mshould expect the next predicted action to lead to better performance than previous trials. The goal is to learn \u001b[0m\n",
       "\u001b[32mthe process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm \u001b[0m\n",
       "\u001b[32mDistillation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThe paper hypothesizes that any algorithm that \u001b[0m\n",
       "\u001b[32mgenerates a set of learning histories can be distilled into a neural network by performing behavioral cloning over \u001b[0m\n",
       "\u001b[32mactions. The history data is generated by a set of source policies, each trained for a specific task. At the \u001b[0m\n",
       "\u001b[32mtraining stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for\u001b[0m\n",
       "\u001b[32mtraining, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, \u001b[0m\n",
       "\u001b[32mso episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are \u001b[0m\n",
       "\u001b[32mnecessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough \u001b[0m\n",
       "\u001b[32mcontext.\\nIn comparison with three baselines, including ED \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexpert distillation, behavior cloning with expert \u001b[0m\n",
       "\u001b[32mtrajectories instead of learning history\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, source policy \u001b[0m\u001b[32m(\u001b[0m\u001b[32mused for generating trajectories for distillation by \u001b[0m\n",
       "\u001b[32mUCB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, RL^2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDuan et al. 2017; used as upper bound since it needs online RL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, AD demonstrates in-context RL with \u001b[0m\n",
       "\u001b[32mperformance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When \u001b[0m\n",
       "\u001b[32mconditioned on partial training history of the source policy, AD also improves much faster than ED \u001b[0m\n",
       "\u001b[32mbaseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and \u001b[0m\n",
       "\u001b[32mexploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and \u001b[0m\n",
       "\u001b[32mDQN for watermaze.\u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nComponent Two: Memory#\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mBig thank you to ChatGPT for helping\u001b[0m\n",
       "\u001b[32mme draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my \u001b[0m\n",
       "\u001b[32mconversations with ChatGPT.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, \u001b[0m\n",
       "\u001b[32mretain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: \u001b[0m\n",
       "\u001b[32mThis is the earliest stage of memory, providing the ability to retain impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, \u001b[0m\n",
       "\u001b[32mauditory, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. \u001b[0m\n",
       "\u001b[32mSubcategories include iconic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, echoic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mauditory\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and haptic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtouch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n\\nShort-Term \u001b[0m\n",
       "\u001b[32mMemory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or Working Memory: It stores information that we are currently aware of and needed to carry out \u001b[0m\n",
       "\u001b[32mcomplex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about\u001b[0m\n",
       "\u001b[32m7 items \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMiller 1956\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: Long-term memory can store \u001b[0m\n",
       "\u001b[32minformation for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage \u001b[0m\n",
       "\u001b[32mcapacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and \u001b[0m\n",
       "\u001b[32mrefers to those memories that can be consciously recalled, including episodic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mevents and experiences\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and \u001b[0m\n",
       "\u001b[32msemantic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfacts and concepts\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nImplicit / procedural memory: This type of memory is unconscious and \u001b[0m\n",
       "\u001b[32minvolves skills and routines that are performed automatically, like riding a bike or typing on a \u001b[0m\n",
       "\u001b[32mkeyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following \u001b[0m\n",
       "\u001b[32mmappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other \u001b[0m\n",
       "\u001b[32mmodalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite \u001b[0m\n",
       "\u001b[32mcontext window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to \u001b[0m\n",
       "\u001b[32mat query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m#\\nThe external memory can \u001b[0m\n",
       "\u001b[32malleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of\u001b[0m\n",
       "\u001b[32minformation into a vector store database that can support fast maximum inner-product search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To optimize the\u001b[0m\n",
       "\u001b[32mretrieval speed, the common choice is the approximate nearest neighbors \u001b[0m\u001b[32m(\u001b[0m\u001b[32mANN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\u200b algorithm to return \u001b[0m\n",
       "\u001b[32mapproximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common \u001b[0m\n",
       "\u001b[32mchoices of ANN algorithms for fast MIPS:\\n\\nLSH \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLocality-Sensitive Hashing\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: It introduces a hashing function such\u001b[0m\n",
       "\u001b[32mthat similar input items are mapped to the same buckets with high probability, where the number of buckets is much \u001b[0m\n",
       "\u001b[32msmaller than the number of inputs.\\nANNOY \u001b[0m\u001b[32m(\u001b[0m\u001b[32mApproximate Nearest Neighbors Oh Yeah\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: The core data structure are \u001b[0m\n",
       "\u001b[32mrandom projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input\u001b[0m\n",
       "\u001b[32mspace into half and each leaf stores one data point. Trees are built independently and at random, so to some \u001b[0m\n",
       "\u001b[32mextent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half \u001b[0m\n",
       "\u001b[32mthat is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more \u001b[0m\n",
       "\u001b[32mscalable.\\nHNSW \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHierarchical Navigable Small World\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: It is inspired by the idea of small world networks where most\u001b[0m\n",
       "\u001b[32mnodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of\u001b[0m\n",
       "\u001b[32msocial networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the \u001b[0m\n",
       "\u001b[32mactual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW \u001b[0m\n",
       "\u001b[32mstarts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves\u001b[0m\n",
       "\u001b[32mdown to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a \u001b[0m\n",
       "\u001b[32mlarge distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFacebook AI\u001b[0m\n",
       "\u001b[32mSimilarity Search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: It operates on the assumption that in high dimensional space, distances between nodes follow a \u001b[0m\n",
       "\u001b[32mGaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by \u001b[0m\n",
       "\u001b[32mpartitioning the vector space into clusters and then refining the quantization within clusters. Search first looks \u001b[0m\n",
       "\u001b[32mfor cluster candidates with coarse quantization and then further looks into each cluster with finer \u001b[0m\n",
       "\u001b[32mquantization.\\nScaNN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mScalable Nearest Neighbors\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: The main innovation in ScaNN is anisotropic vector quantization.\u001b[0m\n",
       "\u001b[32mIt quantizes a data point $x_i$ to $\\\\tilde\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as \u001b[0m\n",
       "\u001b[32msimilar to the original distance of $\\\\angle q, \\\\tilde\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_i$ as possible, instead of picking the closet \u001b[0m\n",
       "\u001b[32mquantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: \u001b[0m\n",
       "\u001b[32mGoogle Blog, 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: \u001b[0m\n",
       "\u001b[32mTool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and \u001b[0m\n",
       "\u001b[32mutilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with \u001b[0m\n",
       "\u001b[32mexternal tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to \u001b[0m\n",
       "\u001b[32mcrack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not \u001b[0m\n",
       "\u001b[32mcomparable with humans. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Animals using tools\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nMRKL \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKarpas et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, short for “Modular \u001b[0m\n",
       "\u001b[32mReasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is \u001b[0m\n",
       "\u001b[32mproposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route \u001b[0m\n",
       "\u001b[32minquiries to the best suitable expert module. These modules can be neural \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. deep learning models\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or symbolic \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. math calculator, currency converter, weather API\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThey did an experiment on fine-tuning LLM to call a \u001b[0m\n",
       "\u001b[32mcalculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math \u001b[0m\n",
       "\u001b[32mproblems than explicitly stated math problems because LLMs \u001b[0m\u001b[32m(\u001b[0m\u001b[32m7B Jurassic1-large model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m failed to extract the right \u001b[0m\n",
       "\u001b[32marguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work \u001b[0m\n",
       "\u001b[32mreliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTool \u001b[0m\n",
       "\u001b[32mAugmented Language Models; Parisi et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Toolformer \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchick et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m fine-tune a LM to learn to use \u001b[0m\n",
       "\u001b[32mexternal tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the \u001b[0m\n",
       "\u001b[32mquality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins \u001b[0m\n",
       "\u001b[32mand OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. \u001b[0m\n",
       "\u001b[32mThe collection of tool APIs can be provided by other developers \u001b[0m\u001b[32m(\u001b[0m\u001b[32mas in Plugins\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or self-defined \u001b[0m\u001b[32m(\u001b[0m\u001b[32mas in function \u001b[0m\n",
       "\u001b[32mcalls\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nHuggingGPT \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a framework to use ChatGPT as the task planner to select models available\u001b[0m\n",
       "\u001b[32min HuggingFace platform according to the model descriptions and summarize the response based on the execution \u001b[0m\n",
       "\u001b[32mresults.\\n\\nFig. 11. Illustration of how HuggingGPT works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe system comprises \u001b[0m\n",
       "\u001b[32mof 4 stages:\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are\u001b[0m\n",
       "\u001b[32mfour attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples \u001b[0m\n",
       "\u001b[32mto guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several \u001b[0m\n",
       "\u001b[32mtasks: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"text\": text, \"image\": URL, \"audio\": \u001b[0m\n",
       "\u001b[32mURL, \"video\": URL\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. The \"dep\" field denotes the id of the previous task which generates a new resource that the \u001b[0m\n",
       "\u001b[32mcurrent task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the \u001b[0m\n",
       "\u001b[32mdependency task with id as task_id. The task MUST be selected from the following options: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Available Task List \u001b[0m\n",
       "\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you\u001b[0m\n",
       "\u001b[32mneed to reply empty JSON. Here are several cases for your reference: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Demonstrations \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. The chat history is \u001b[0m\n",
       "\u001b[32mrecorded as \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Chat History \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. From this chat history, you can find the path of the user-mentioned resources for \u001b[0m\n",
       "\u001b[32myour task planning.\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Model selection: LLM distributes the tasks to expert models, where the request is framed\u001b[0m\n",
       "\u001b[32mas a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context \u001b[0m\n",
       "\u001b[32mlength, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI \u001b[0m\n",
       "\u001b[32massistant helps the user to select a suitable model from a list of models to process the user request. The AI \u001b[0m\n",
       "\u001b[32massistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \u001b[0m\n",
       "\u001b[32m\"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mCandidate Models \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Please select one model from the list.\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task execution: Expert models execute on the \u001b[0m\n",
       "\u001b[32mspecific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs \u001b[0m\n",
       "\u001b[32mto describe the process and results. The previous stages can be formed as - User Input: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m User Input \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task \u001b[0m\n",
       "\u001b[32mPlanning: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Tasks \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Model Selection: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Model Assignment \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Execution: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Predictions \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. You must first \u001b[0m\n",
       "\u001b[32manswer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and \u001b[0m\n",
       "\u001b[32mmodel inference results to the user in the first person. If inference results contain a file path, must tell the \u001b[0m\n",
       "\u001b[32muser the complete file path.\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Response generation: LLM receives the execution results and provides summarized\u001b[0m\n",
       "\u001b[32mresults to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Efficiency \u001b[0m\n",
       "\u001b[32mimprovement is needed as both LLM inference rounds and interactions with other models slow down the process; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m It\u001b[0m\n",
       "\u001b[32mrelies on a long context window to communicate over complicated task content; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Stability improvement of LLM \u001b[0m\n",
       "\u001b[32moutputs and external model services.\\nAPI-Bank \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLi et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a benchmark for evaluating the performance of \u001b[0m\n",
       "\u001b[32mtool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 \u001b[0m\n",
       "\u001b[32mannotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, \u001b[0m\n",
       "\u001b[32mcalculator, calendar queries, smart home control, schedule management, health data management, account \u001b[0m\n",
       "\u001b[32mauthentication workflow and more. Because there are a large number of APIs, LLM first has access to API search \u001b[0m\n",
       "\u001b[32mengine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. \u001b[0m\n",
       "\u001b[32mPseudo code of how LLM makes an API call in API-Bank. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Li et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nIn the API-Bank workflow, \u001b[0m\n",
       "\u001b[32mLLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions \u001b[0m\n",
       "\u001b[32minclude:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to \u001b[0m\n",
       "\u001b[32miteratively modify the API inputs \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. deciding search keywords for Search Engine API\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nResponse based on the API\u001b[0m\n",
       "\u001b[32mresults: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates \u001b[0m\n",
       "\u001b[32mthe agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s\u001b[0m\n",
       "\u001b[32mdescription, the model needs to determine whether to call a given API, call it correctly, and respond properly to \u001b[0m\n",
       "\u001b[32mAPI returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that \u001b[0m\n",
       "\u001b[32mmay solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability \u001b[0m\n",
       "\u001b[32mto plan API beyond retrieve and call. Given unclear user requests \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. schedule group meetings, book \u001b[0m\n",
       "\u001b[32mflight/hotel/restaurant for a trip\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, the model may have to conduct multiple API calls to solve it.\\n\\nCase \u001b[0m\n",
       "\u001b[32mStudies#\\nScientific Discovery Agent#\\nChemCrow \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBran et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a domain-specific example in which LLM is \u001b[0m\n",
       "\u001b[32maugmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials\u001b[0m\n",
       "\u001b[32mdesign. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and \u001b[0m\n",
       "\u001b[32mcombines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, \u001b[0m\n",
       "\u001b[32mdescriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a \u001b[0m\n",
       "\u001b[32muser-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct \u001b[0m\n",
       "\u001b[32mformat - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based \u001b[0m\n",
       "\u001b[32mevaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented \u001b[0m\n",
       "\u001b[32mtowards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large \u001b[0m\n",
       "\u001b[32mmargin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires \u001b[0m\n",
       "\u001b[32mdeep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the \u001b[0m\n",
       "\u001b[32mcorrectness of task results.\\nBoiko et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m also looked into LLM-empowered agents for scientific discovery, \u001b[0m\n",
       "\u001b[32mto handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools \u001b[0m\n",
       "\u001b[32mto browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other \u001b[0m\n",
       "\u001b[32mLLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following \u001b[0m\n",
       "\u001b[32mreasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a \u001b[0m\n",
       "\u001b[32mscaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey \u001b[0m\n",
       "\u001b[32malso discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list\u001b[0m\n",
       "\u001b[32mof known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests \u001b[0m\u001b[32m(\u001b[0m\u001b[32m36%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m were accepted to\u001b[0m\n",
       "\u001b[32mobtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 \u001b[0m\n",
       "\u001b[32mwere rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt\u001b[0m\n",
       "\u001b[32monly.\\nGenerative Agents Simulation#\\nGenerative Agents \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPark, et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is super fun experiment where 25 \u001b[0m\n",
       "\u001b[32mvirtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, \u001b[0m\n",
       "\u001b[32minspired by The Sims. Generative agents create believable simulacra of human behavior for interactive \u001b[0m\n",
       "\u001b[32mapplications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to \u001b[0m\n",
       "\u001b[32menable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream:\u001b[0m\n",
       "\u001b[32mis a long-term memory module \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexternal database\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that records a comprehensive list of agents’ experience in natural\u001b[0m\n",
       "\u001b[32mlanguage.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication \u001b[0m\n",
       "\u001b[32mcan trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s \u001b[0m\n",
       "\u001b[32mbehavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance:\u001b[0m\n",
       "\u001b[32mdistinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current \u001b[0m\n",
       "\u001b[32msituation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and \u001b[0m\n",
       "\u001b[32mguides the agent’s future behavior. They are higher-level summaries of past events \u001b[0m\u001b[32m(\u001b[0m\u001b[32m<\u001b[0m\u001b[32m-\u001b[0m\u001b[32m note that this is a bit \u001b[0m\n",
       "\u001b[32mdifferent from self-reflection above\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient\u001b[0m\n",
       "\u001b[32mhigh-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning &\u001b[0m\n",
       "\u001b[32mReacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in \u001b[0m\n",
       "\u001b[32morder to optimize believability at the moment vs in time.\\nPrompt template: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mIntro of an agent X\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Here is X\\'s \u001b[0m\n",
       "\u001b[32mplan today in broad strokes: 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nRelationships between agents and observations of one agent by another are all \u001b[0m\n",
       "\u001b[32mtaken into consideration for planning and reacting.\\nEnvironment information is present in a tree \u001b[0m\n",
       "\u001b[32mstructure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis fun \u001b[0m\n",
       "\u001b[32msimulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two agents\u001b[0m\n",
       "\u001b[32mcontinuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal \u001b[0m\n",
       "\u001b[32mcomplications.\\n\\nGOALS:\\n\\n1. \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided goal 1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n2. \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided goal 2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n3. ...\\n4. ...\\n5. \u001b[0m\n",
       "\u001b[32m...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately \u001b[0m\n",
       "\u001b[32msave important information to files.\\n2. If you are unsure how you previously did something or want to recall past \u001b[0m\n",
       "\u001b[32mevents, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the \u001b[0m\n",
       "\u001b[32mcommands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate \u001b[0m\n",
       "\u001b[32mwithin a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \u001b[0m\n",
       "\u001b[32m\"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \u001b[0m\n",
       "\u001b[32m\"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \u001b[0m\n",
       "\u001b[32m\"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete \u001b[0m\n",
       "\u001b[32mGPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \u001b[0m\n",
       "\u001b[32m\"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \u001b[0m\n",
       "\u001b[32m\"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \u001b[0m\n",
       "\u001b[32m\"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \u001b[0m\n",
       "\u001b[32m\"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \u001b[0m\n",
       "\u001b[32m\"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \u001b[0m\n",
       "\u001b[32m\"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \u001b[0m\n",
       "\u001b[32m\"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate \u001b[0m\n",
       "\u001b[32mImage: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do \u001b[0m\n",
       "\u001b[32mNothing: \"do_nothing\", args:\\n20. Task Complete \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShutdown\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: \"task_complete\", args: \"reason\": \u001b[0m\n",
       "\u001b[32m\"<reason\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory \u001b[0m\n",
       "\u001b[32mmanagement.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance \u001b[0m\n",
       "\u001b[32mEvaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your \u001b[0m\n",
       "\u001b[32mabilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions \u001b[0m\n",
       "\u001b[32mand strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete \u001b[0m\n",
       "\u001b[32mtasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse \u001b[0m\n",
       "\u001b[32mFormat:\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"thoughts\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- \u001b[0m\n",
       "\u001b[32mshort bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n   \u001b[0m\n",
       "\u001b[32m\"speak\": \"thoughts summary to say to user\"\\n    \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n    \"command\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n        \"name\": \"command name\",\\n        \u001b[0m\n",
       "\u001b[32m\"args\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n            \"arg name\": \"value\"\\n        \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n    \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nEnsure the response can be parsed by Python \u001b[0m\n",
       "\u001b[32mjson.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural \u001b[0m\n",
       "\u001b[32mlanguage. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input\u001b[0m\n",
       "\u001b[32mto clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI \u001b[0m\n",
       "\u001b[32mChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser input text\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \u001b[0m\n",
       "\u001b[32m\"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify \u001b[0m\n",
       "\u001b[32mthem.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need \u001b[0m\n",
       "\u001b[32mclarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n\u001b[0m\n",
       "\u001b[32m\"role\": \"user\",\\n    \"content\": \"We are writing \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32ma Super Mario game in python. MVC components split in separate \u001b[0m\n",
       "\u001b[32mfiles. Keyboard control.\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need \u001b[0m\n",
       "\u001b[32mclarification:\\\\n1. Specifics of the Super Mario game \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. level design, characters, gameplay mechanics\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n2. \u001b[0m\n",
       "\u001b[32mDetails about the MVC components \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. which components are in each file\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n3. Keyboard control implementation \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g. which keys to use, how to handle input\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the \u001b[0m\n",
       "\u001b[32mSuper Mario game, such as level design, characters, and gameplay mechanics?\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \u001b[0m\n",
       "\u001b[32m\"content\": \"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mThere are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It \u001b[0m\n",
       "\u001b[32mis a classical platform game just like Super Mario. The main character moves from left to right, trying to get to \u001b[0m\n",
       "\u001b[32mthe destination, where there are many obstacles and attacks from enemies in the process.\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n\\\\nIs anything else \u001b[0m\n",
       "\u001b[32munclear? If yes, only answer in the form:\\\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mremaining unclear areas\u001b[0m\u001b[32m}\u001b[0m\u001b[32m remaining questions.\\\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mNext question\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\nIf \u001b[0m\n",
       "\u001b[32meverything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \u001b[0m\n",
       "\u001b[32m\"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information \u001b[0m\n",
       "\u001b[32mabout how the MVC components are split into separate files?\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \"content\": \u001b[0m\n",
       "\u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mMake your own assumptions and state them explicitly before starting\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nThen after these clarification, \u001b[0m\n",
       "\u001b[32mthe agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get \u001b[0m\n",
       "\u001b[32minstructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture\u001b[0m\n",
       "\u001b[32mis, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented \u001b[0m\n",
       "\u001b[32mas code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will \u001b[0m\n",
       "\u001b[32mfirst lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment \u001b[0m\n",
       "\u001b[32mon their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly \u001b[0m\n",
       "\u001b[32mfollow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the \u001b[0m\n",
       "\u001b[32mlowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, \u001b[0m\n",
       "\u001b[32mand CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are \u001b[0m\n",
       "\u001b[32mimported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a\u001b[0m\n",
       "\u001b[32mlanguage and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports,\u001b[0m\n",
       "\u001b[32mtypes etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if\u001b[0m\n",
       "\u001b[32myou are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency \u001b[0m\n",
       "\u001b[32mdefinition file.\\nBefore you finish, double check that all parts of the architecture is present in the \u001b[0m\n",
       "\u001b[32mfiles.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create\u001b[0m\n",
       "\u001b[32man appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always \u001b[0m\n",
       "\u001b[32madd a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very \u001b[0m\n",
       "\u001b[32mcomplex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the\u001b[0m\n",
       "\u001b[32mcode written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin \u001b[0m\n",
       "\u001b[32msamples:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will \u001b[0m\n",
       "\u001b[32mwrite a very long answer. Make sure that every detail of the architecture is, in the end, implemented as \u001b[0m\n",
       "\u001b[32mcode.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by \u001b[0m\n",
       "\u001b[32mstep and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of\u001b[0m\n",
       "\u001b[32mthe core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen\u001b[0m\n",
       "\u001b[32myou will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block\u001b[0m\n",
       "\u001b[32mformat, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the \u001b[0m\n",
       "\u001b[32mfile extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the \u001b[0m\n",
       "\u001b[32mcode:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones \u001b[0m\n",
       "\u001b[32mthat are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No \u001b[0m\n",
       "\u001b[32mplaceholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure \u001b[0m\n",
       "\u001b[32mthat files contain all imports, types etc. Make sure that code in different files are compatible with each \u001b[0m\n",
       "\u001b[32mother.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module \u001b[0m\n",
       "\u001b[32mdependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the \u001b[0m\n",
       "\u001b[32marchitecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different \u001b[0m\n",
       "\u001b[32mfiles.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an \u001b[0m\n",
       "\u001b[32mappropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function \u001b[0m\n",
       "\u001b[32mdefinition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices\u001b[0m\n",
       "\u001b[32mfor the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython \u001b[0m\n",
       "\u001b[32mtoolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n #  … same conversation as earlier, ended with \"Make \u001b[0m\n",
       "\u001b[32myour own assumptions and state them explicitly before starting\".\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"assistant\",\\n    \"content\": \u001b[0m\n",
       "\u001b[32m\"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and\u001b[0m\n",
       "\u001b[32menemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, \u001b[0m\n",
       "\u001b[32mbackgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard \u001b[0m\n",
       "\u001b[32mcontrols, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of \u001b[0m\n",
       "\u001b[32mthe keyboard control implementation you would like me to clarify?\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \"content\": \u001b[0m\n",
       "\u001b[32m\"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we \u001b[0m\n",
       "\u001b[32mget it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as \u001b[0m\n",
       "\u001b[32ma quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach \u001b[0m\n",
       "\u001b[32mfile must strictly follow a markdown code block format, where the following tokens must be replaced such \u001b[0m\n",
       "\u001b[32mthat\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language \u001b[0m\n",
       "\u001b[32mfor the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code\u001b[0m\n",
       "\u001b[32mshould be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the \u001b[0m\n",
       "\u001b[32mones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file \u001b[0m\n",
       "\u001b[32mnaming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make\u001b[0m\n",
       "\u001b[32msure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts \u001b[0m\n",
       "\u001b[32mof the architecture is present in the files.\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nChallenges#\\nAfter going through key ideas and demos of \u001b[0m\n",
       "\u001b[32mbuilding LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The \u001b[0m\n",
       "\u001b[32mrestricted context capacity limits the inclusion of historical information, detailed instructions, API call \u001b[0m\n",
       "\u001b[32mcontext, and responses. The design of the system has to work with this limited communication bandwidth, while \u001b[0m\n",
       "\u001b[32mmechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context \u001b[0m\n",
       "\u001b[32mwindows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation \u001b[0m\n",
       "\u001b[32mpower is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning \u001b[0m\n",
       "\u001b[32mover a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust \u001b[0m\n",
       "\u001b[32mplans when faced with unexpected errors, making them less robust compared to humans who learn from trial and \u001b[0m\n",
       "\u001b[32merror.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an \u001b[0m\n",
       "\u001b[32minterface between LLMs and external components such as memory and tools. However, the reliability of model outputs \u001b[0m\n",
       "\u001b[32mis questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. refuse to \u001b[0m\n",
       "\u001b[32mfollow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article\u001b[0m\u001b[32m{\u001b[0m\u001b[32mweng2023agent,\\n  title   = \"LLM-powered \u001b[0m\n",
       "\u001b[32mAutonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month\u001b[0m\n",
       "\u001b[32m= \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nReferences#\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wei et al. “Chain\u001b[0m\n",
       "\u001b[32mof thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. “Tree of Thoughts: \u001b[0m\n",
       "\u001b[32mDliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. \u001b[0m\n",
       "\u001b[32m“Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al.\u001b[0m\n",
       "\u001b[32m“LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Google Blog. \u001b[0m\n",
       "\u001b[32m“Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mhttps://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Shinn & Labash. “Reflexion: an autonomous \u001b[0m\n",
       "\u001b[32magent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Laskin et al. \u001b[0m\n",
       "\u001b[32m“In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Karpas et al. “MRKL Systems A \u001b[0m\n",
       "\u001b[32mmodular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete \u001b[0m\n",
       "\u001b[32mreasoning.” arXiv preprint arXiv:2205.00445 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Nakano et al. “Webgpt: Browser-assisted \u001b[0m\n",
       "\u001b[32mquestion-answering with human feedback.” arXiv preprint arXiv:2112.09332 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Parisi et al. “TALM: Tool \u001b[0m\n",
       "\u001b[32mAugmented Language Models”\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” \u001b[0m\n",
       "\u001b[32marXiv preprint arXiv:2302.04761 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Li \u001b[0m\n",
       "\u001b[32met al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m16\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Shen et al. \u001b[0m\n",
       "\u001b[32m“HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m17\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint \u001b[0m\n",
       "\u001b[32marXiv:2304.05376 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m18\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Boiko et al. “Emergent autonomous scientific research capabilities of large language\u001b[0m\n",
       "\u001b[32mmodels.” arXiv preprint arXiv:2304.05332 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m19\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Joon Sung Park, et al. “Generative Agents: Interactive \u001b[0m\n",
       "\u001b[32mSimulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m20\u001b[0m\u001b[32m]\u001b[0m\u001b[32m AutoGPT. \u001b[0m\n",
       "\u001b[32mhttps://github.com/Significant-Gravitas/Auto-GPT\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m21\u001b[0m\u001b[32m]\u001b[0m\u001b[32m GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the capability to retain and recall (infinite) information over extended periods, often by leveraging an external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is missing from the model weights (often hard to change after pre-training), including current information, code </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execution capability, access to proprietary information sources and more.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manageable tasks and shed lights into an interpretation of the model’s thinking process.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">space to be a combination of task-specific discrete actions and the language space. The former enables LLM to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">where Thought: … step is removed.\\nReflexion (Shinn &amp; Labash 2023) is a framework to equip agents with dynamic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the reward model provides a simple binary reward and the action space follows the setup in ReAct where the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">depending on the self-reflection results.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn &amp; Labash, 2023)\\nThe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">encountering a sequence of consecutive identical actions that lead to the same observation in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">working memory, up to three, to be used as context for querying LLM.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inefficient planning in AlfWorld. (Image source: Shinn &amp; Labash, 2023)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model can optionally receive multiple rounds of instructions with human annotators at test time.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that an agent interacts with the environment many times and in each episode the agent gets a little better, AD </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task-specific policy itself.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a neural network by performing behavioral cloning over actions. The history data is generated by a set of source </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reality, the model has limited context window length, so episodes should be short enough to construct multi-episode</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">emergence of in-context RL requires long enough context.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In comparison with three baselines, including ED (expert distillation, behavior cloning with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expert trajectories instead of learning history), source policy (used for generating trajectories for distillation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory of facts and events, and refers to those memories that can be consciously recalled, including episodic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mappings:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 8. Categorization of human memory.\\nWe can roughly consider the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at query time, accessible via fast retrieval.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Maximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">finite attention span.  A standard practice is to save the embedding representation of information into a vector </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fast MIPS:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation”</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">potentially cover a large distance in the data space, and each move in the lower layers refines the search </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quality.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'FAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">$\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of picking the closet quantization centroid points.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">can significantly extend the model capabilities.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details in the “External APIs” section of Prompt Engineering.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the task planner to select models available in HuggingFace platform according to the model descriptions and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarize the response based on the execution results.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">examples to guide LLM to do task parsing and planning.\\nInstruction:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\":</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the id of the previous task which generates a new resource that the current task relies on. A special tag </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">history, you can find the path of the user-mentioned resources for your task planning.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'(2) Model selection: LLM distributes the tasks to expert models, where the request is framed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistant helps the user to select a suitable model from a list of models to process the user request. The AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific tasks and log results.\\nInstruction:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"(3) Task execution: Expert models execute on the specific tasks and log </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">straightforward manner. Then describe the task process and show your analysis and model inference results to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user in the first person. If inference results contain a file path, must tell the user the complete file path.\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'(4) Response generation: LLM receives the execution results and provides summarized results </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">external model services.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">queries, smart home control, schedule management, health data management, account authentication workflow and more.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and then uses the corresponding documentation to make a call.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API).\\nResponse based on the API results: the model can choose to refine and call again if results are not </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'This benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple API calls to solve it.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Case Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the ReAct format - Thought, Action, Action Input, Observation.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'They also discussed the risks, especially with illicit drugs and bioweapons. They developed a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Memory stream: is a long-term memory module (external database) that records a comprehensive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(&lt;- note that this is a bit different from self-reflection above)'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Prompt LM with 100 most recent observations and to generate 3 most salient high-level </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning &amp; Reacting: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\"</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">continuing the conversation topic) and coordination of social events (e.g. host a party and invite many </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">save important information to files.\\n2. If you are unsure how you previously did something or want to recall past </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">within a few minutes'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Commands:\\n1. Google Search: \"google\", args: \"input\": \"&lt;search&gt;\"\\n2. Browse Website: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"browse_website\", args: \"url\": \"&lt;url&gt;\", \"question\": \"&lt;what_you_want_to_find_on_website&gt;\"\\n3. Start GPT Agent: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"start_agent\", args: \"name\": \"&lt;name&gt;\", \"task\": \"&lt;short_task_desc&gt;\", \"prompt\": \"&lt;prompt&gt;\"\\n4. Message GPT Agent: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"message_agent\", args: \"key\": \"&lt;key&gt;\", \"message\": \"&lt;message&gt;\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPT Agent: \"delete_agent\", args: \"key\": \"&lt;key&gt;\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;url&gt;\", \"clone_path\": \"&lt;directory&gt;\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"&lt;file&gt;\", \"text\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;text&gt;\"\\n9. Read file: \"read_file\", args: \"file\": \"&lt;file&gt;\"\\n10. Append to file: \"append_to_file\", args: \"file\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;file&gt;\", \"text\": \"&lt;text&gt;\"\\n11. Delete file: \"delete_file\", args: \"file\": \"&lt;file&gt;\"\\n12. Search Files: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"search_files\", args: \"directory\": \"&lt;directory&gt;\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;full_code_string&gt;\"'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'11. Delete file: \"delete_file\", args: \"file\": \"&lt;file&gt;\"\\n12. Search Files: \"search_files\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">args: \"directory\": \"&lt;directory&gt;\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"&lt;full_code_string&gt;\"\\n14. Get </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Improved Code: \"improve_code\", args: \"suggestions\": \"&lt;list_of_suggestions&gt;\", \"code\": \"&lt;full_code_string&gt;\"\\n15. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Write Tests: \"write_tests\", args: \"code\": \"&lt;full_code_string&gt;\", \"focus\": \"&lt;list_of_focus_areas&gt;\"\\n16. Execute </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Python File: \"execute_python_file\", args: \"file\": \"&lt;file&gt;\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;prompt&gt;\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"&lt;text&gt;\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Complete (Shutdown): \"task_complete\", args: \"reason\": \"&lt;reason&gt;\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks in the least number of steps.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n-</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is instructed to think over a list of smaller components to build and ask for user input to clarify questions as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"role\": \"assistant\",'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{\\n    \"role\": \"user\",'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The main character moves from left to right, trying to get to the destination, where there are many obstacles and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different system message.\\nSystem message:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You will get instructions for code to write.\\nYou will write a very long answer. Make sure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">then go to the ones that are imported by that file, and so on.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'FILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">definition file.\\nBefore you finish, double check that all parts of the architecture is present in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex bits of logic.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You always add a comment briefly describing the purpose of the function definition.\\nYou try </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'pytest\\ndataclasses'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Conversatin samples:\\n[\\n  {\\n    \"role\": \"system\",'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">describing the purpose of'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'},\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code block language for the code\\'s language, and CODE is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that files contain all imports, types etc. The code should be fully'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'are imported by that file, and so on.\\\\nFollow a language and framework appropriate best </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">check that all parts of the architecture is present in the files.\\\\n\"'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">start to see a couple common limitations:'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Finite context length: The restricted context capacity limits the inclusion of historical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information, detailed instructions, API call context, and responses. The design of the system has to work with this</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">compared to humans who learn from trial and error.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Reliability of natural language interface: Current agent system relies on natural language as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an interface between LLMs and external components such as memory and tools. However, the reliability of model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://lilianweng.github.io/posts/2023-06-23-agent/.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Efficient Vector Similarity Search” July 28, 2020.\\n[7] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn &amp; Labash. “Reflexion: an autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  \u001b[0m\n",
       "\u001b[32m|  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlarge language model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as its core controller is a cool \u001b[0m\n",
       "\u001b[32mconcept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. \u001b[0m\n",
       "\u001b[32mThe potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be \u001b[0m\n",
       "\u001b[32mframed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM\u001b[0m\n",
       "\u001b[32mfunctions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: \u001b[0m\n",
       "\u001b[32mThe agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex \u001b[0m\n",
       "\u001b[32mtasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn \u001b[0m\n",
       "\u001b[32mfrom mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Memory\\n\\nShort-term memory: I would consider all the in-context learning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSee Prompt \u001b[0m\n",
       "\u001b[32mEngineering\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with \u001b[0m\n",
       "\u001b[32mthe capability to retain and recall \u001b[0m\u001b[32m(\u001b[0m\u001b[32minfinite\u001b[0m\u001b[32m)\u001b[0m\u001b[32m information over extended periods, often by leveraging an external \u001b[0m\n",
       "\u001b[32mvector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that\u001b[0m\n",
       "\u001b[32mis missing from the model weights \u001b[0m\u001b[32m(\u001b[0m\u001b[32moften hard to change after pre-training\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, including current information, code \u001b[0m\n",
       "\u001b[32mexecution capability, access to proprietary information sources and more.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA \u001b[0m\n",
       "\u001b[32mcomplicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask \u001b[0m\n",
       "\u001b[32mDecomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has become a standard prompting technique for enhancing \u001b[0m\n",
       "\u001b[32mmodel performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time \u001b[0m\n",
       "\u001b[32mcomputation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple \u001b[0m\n",
       "\u001b[32mmanageable tasks and shed lights into an interpretation of the model’s thinking process.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Tree of Thoughts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m extends CoT by exploring multiple reasoning possibilities \u001b[0m\n",
       "\u001b[32mat each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step,\u001b[0m\n",
       "\u001b[32mcreating a tree structure. The search process can be BFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbreadth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or DFS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mdepth-first search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[32meach state evaluated by a classifier \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvia a prompt\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or majority vote.\\nTask decomposition can be done \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by LLM \u001b[0m\n",
       "\u001b[32mwith simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by using \u001b[0m\n",
       "\u001b[32mtask-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with human inputs.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Another quite distinct approach, LLM+P \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, involves relying on an external \u001b[0m\n",
       "\u001b[32mclassical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mPDDL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as an intermediate interface to describe the planning problem. In this process, LLM \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m translates the \u001b[0m\n",
       "\u001b[32mproblem into “Problem PDDL”, then \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m requests a classical planner to generate a PDDL plan based on an existing \u001b[0m\n",
       "\u001b[32m“Domain PDDL”, and finally \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m translates the PDDL plan back into natural language. Essentially, the planning step \u001b[0m\n",
       "\u001b[32mis outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which \u001b[0m\n",
       "\u001b[32mis common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital \u001b[0m\n",
       "\u001b[32maspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting \u001b[0m\n",
       "\u001b[32mprevious mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'ReAct \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m integrates reasoning and acting within LLM by extending the action \u001b[0m\n",
       "\u001b[32mspace to be a combination of task-specific discrete actions and the language space. The former enables LLM to \u001b[0m\n",
       "\u001b[32minteract with the environment \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. use Wikipedia search API\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, while the latter prompting LLM to generate reasoning\u001b[0m\n",
       "\u001b[32mtraces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly \u001b[0m\n",
       "\u001b[32mformatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRepeated many times\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. HotpotQA, \u001b[0m\n",
       "\u001b[32mFEVER\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and decision-making tasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. AlfWorld Env, WebShop\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Yao et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nIn both \u001b[0m\n",
       "\u001b[32mexperiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline \u001b[0m\n",
       "\u001b[32mwhere Thought: … step is removed.\\nReflexion \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShinn & Labash 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a framework to equip agents with dynamic \u001b[0m\n",
       "\u001b[32mmemory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which \u001b[0m\n",
       "\u001b[32mthe reward model provides a simple binary reward and the action space follows the setup in ReAct where the \u001b[0m\n",
       "\u001b[32mtask-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, \u001b[0m\n",
       "\u001b[32mthe agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial \u001b[0m\n",
       "\u001b[32mdepending on the self-reflection results.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 3. Illustration of the Reflexion framework. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shinn & Labash, 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe \u001b[0m\n",
       "\u001b[32mheuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. \u001b[0m\n",
       "\u001b[32mInefficient planning refers to trajectories that take too long without success. Hallucination is defined as \u001b[0m\n",
       "\u001b[32mencountering a sequence of consecutive identical actions that lead to the same observation in the \u001b[0m\n",
       "\u001b[32menvironment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfailed \u001b[0m\n",
       "\u001b[32mtrajectory, ideal reflection for guiding future changes in the plan\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Then reflections are added into the agent’s \u001b[0m\n",
       "\u001b[32mworking memory, up to three, to be used as context for querying LLM.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than\u001b[0m\n",
       "\u001b[32minefficient planning in AlfWorld. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shinn & Labash, 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Chain of Hindsight \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoH; Liu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m encourages the model to improve on its own outputs \u001b[0m\n",
       "\u001b[32mby explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a\u001b[0m\n",
       "\u001b[32mcollection of $D_h = \\\\\u001b[0m\u001b[32m{\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx, y_i , r_i , z_i\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^n$, where $x$ is the prompt, each $y_i$ is a model \u001b[0m\n",
       "\u001b[32mcompletion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. \u001b[0m\n",
       "\u001b[32mAssume the feedback tuples are ranked by reward, $r_n \\\\geq r_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mn-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\geq \\\\dots \\\\geq r_1$ The process is \u001b[0m\n",
       "\u001b[32msupervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx, z_i, y_i, z_j, y_j, \\\\dots, z_n, \u001b[0m\n",
       "\u001b[32my_n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the \u001b[0m\n",
       "\u001b[32msequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The \u001b[0m\n",
       "\u001b[32mmodel can optionally receive multiple rounds of instructions with human annotators at test time.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the \u001b[0m\n",
       "\u001b[32mpre-training dataset. To avoid shortcutting and copying \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbecause there are many common words in feedback \u001b[0m\n",
       "\u001b[32msequences\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments \u001b[0m\n",
       "\u001b[32mis a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with\u001b[0m\n",
       "\u001b[32mincremental improvement in a sequence. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Liu et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe idea of CoH is to present a history of \u001b[0m\n",
       "\u001b[32msequentially improved outputs  in context and train the model to take on the trend to produce better outputs. \u001b[0m\n",
       "\u001b[32mAlgorithm Distillation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAD; Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m applies the same idea to cross-episode trajectories in \u001b[0m\n",
       "\u001b[32mreinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering \u001b[0m\n",
       "\u001b[32mthat an agent interacts with the environment many times and in each episode the agent gets a little better, AD \u001b[0m\n",
       "\u001b[32mconcatenates this learning history and feeds that into the model. Hence we should expect the next predicted action \u001b[0m\n",
       "\u001b[32mto lead to better performance than previous trials. The goal is to learn the process of RL instead of training a \u001b[0m\n",
       "\u001b[32mtask-specific policy itself.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 6. Illustration of how Algorithm Distillation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into \u001b[0m\n",
       "\u001b[32ma neural network by performing behavioral cloning over actions. The history data is generated by a set of source \u001b[0m\n",
       "\u001b[32mpolicies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and\u001b[0m\n",
       "\u001b[32ma subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn \u001b[0m\n",
       "\u001b[32mreality, the model has limited context window length, so episodes should be short enough to construct multi-episode\u001b[0m\n",
       "\u001b[32mhistory. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The\u001b[0m\n",
       "\u001b[32memergence of in-context RL requires long enough context.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'In comparison with three baselines, including ED \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexpert distillation, behavior cloning with \u001b[0m\n",
       "\u001b[32mexpert trajectories instead of learning history\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, source policy \u001b[0m\u001b[32m(\u001b[0m\u001b[32mused for generating trajectories for distillation \u001b[0m\n",
       "\u001b[32mby UCB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, RL^2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDuan et al. 2017; used as upper bound since it needs online RL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, AD demonstrates in-context RL with \u001b[0m\n",
       "\u001b[32mperformance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When \u001b[0m\n",
       "\u001b[32mconditioned on partial training history of the source policy, AD also improves much faster than ED baseline.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and \u001b[0m\n",
       "\u001b[32mexploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and \u001b[0m\n",
       "\u001b[32mDQN for watermaze.\u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Laskin et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nComponent Two: Memory#\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mBig thank you to ChatGPT for helping\u001b[0m\n",
       "\u001b[32mme draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my \u001b[0m\n",
       "\u001b[32mconversations with ChatGPT.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, \u001b[0m\n",
       "\u001b[32mretain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: \u001b[0m\n",
       "\u001b[32mThis is the earliest stage of memory, providing the ability to retain impressions of sensory information \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual, \u001b[0m\n",
       "\u001b[32mauditory, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. \u001b[0m\n",
       "\u001b[32mSubcategories include iconic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvisual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, echoic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mauditory\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and haptic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtouch\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Short-Term Memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or Working Memory: It stores information that we are currently aware \u001b[0m\n",
       "\u001b[32mof and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to\u001b[0m\n",
       "\u001b[32mhave the capacity of about 7 items \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMiller 1956\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLTM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: \u001b[0m\n",
       "\u001b[32mLong-term memory can store information for a remarkably long time, ranging from a few days to decades, with an \u001b[0m\n",
       "\u001b[32messentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is \u001b[0m\n",
       "\u001b[32mmemory of facts and events, and refers to those memories that can be consciously recalled, including episodic \u001b[0m\n",
       "\u001b[32mmemory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mevents and experiences\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and semantic memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32mfacts and concepts\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nImplicit / procedural memory: This type \u001b[0m\n",
       "\u001b[32mof memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or \u001b[0m\n",
       "\u001b[32mtyping on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following \u001b[0m\n",
       "\u001b[32mmappings:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 8. Categorization of human memory.\\nWe can roughly consider the following \u001b[0m\n",
       "\u001b[32mmappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other \u001b[0m\n",
       "\u001b[32mmodalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite \u001b[0m\n",
       "\u001b[32mcontext window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to \u001b[0m\n",
       "\u001b[32mat query time, accessible via fast retrieval.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Maximum Inner Product Search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m#\\nThe external memory can alleviate the restriction of \u001b[0m\n",
       "\u001b[32mfinite attention span.  A standard practice is to save the embedding representation of information into a vector \u001b[0m\n",
       "\u001b[32mstore database that can support fast maximum inner-product search \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMIPS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To optimize the retrieval speed, the \u001b[0m\n",
       "\u001b[32mcommon choice is the approximate nearest neighbors \u001b[0m\u001b[32m(\u001b[0m\u001b[32mANN\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\u200b algorithm to return approximately top k nearest \u001b[0m\n",
       "\u001b[32mneighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for \u001b[0m\n",
       "\u001b[32mfast MIPS:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LSH \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLocality-Sensitive Hashing\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: It introduces a hashing function such that similar input \u001b[0m\n",
       "\u001b[32mitems are mapped to the same buckets with high probability, where the number of buckets is much smaller than the \u001b[0m\n",
       "\u001b[32mnumber of inputs.\\nANNOY \u001b[0m\u001b[32m(\u001b[0m\u001b[32mApproximate Nearest Neighbors Oh Yeah\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: The core data structure are random projection \u001b[0m\n",
       "\u001b[32mtrees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half \u001b[0m\n",
       "\u001b[32mand each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a \u001b[0m\n",
       "\u001b[32mhashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to \u001b[0m\n",
       "\u001b[32mthe query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'HNSW \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHierarchical Navigable Small World\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: It is inspired by the idea of small world networks\u001b[0m\n",
       "\u001b[32mwhere most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation”\u001b[0m\n",
       "\u001b[32mfeature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers \u001b[0m\n",
       "\u001b[32mcontain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a \u001b[0m\n",
       "\u001b[32msearch, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any \u001b[0m\n",
       "\u001b[32mcloser, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can \u001b[0m\n",
       "\u001b[32mpotentially cover a large distance in the data space, and each move in the lower layers refines the search \u001b[0m\n",
       "\u001b[32mquality.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'FAISS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFacebook AI Similarity Search\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: It operates on the assumption that in high dimensional\u001b[0m\n",
       "\u001b[32mspace, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data \u001b[0m\n",
       "\u001b[32mpoints. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the \u001b[0m\n",
       "\u001b[32mquantization within clusters. Search first looks for cluster candidates with coarse quantization and then further \u001b[0m\n",
       "\u001b[32mlooks into each cluster with finer quantization.\\nScaNN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mScalable Nearest Neighbors\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: The main innovation in ScaNN \u001b[0m\n",
       "\u001b[32mis anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_i$ such that the inner product \u001b[0m\n",
       "\u001b[32m$\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m_i$ as possible, instead\u001b[0m\n",
       "\u001b[32mof picking the closet quantization centroid points.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 9. Comparison of MIPS algorithms, measured in recall@10. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Google Blog, \u001b[0m\n",
       "\u001b[32m2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool \u001b[0m\n",
       "\u001b[32mUse#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize \u001b[0m\n",
       "\u001b[32mexternal objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools \u001b[0m\n",
       "\u001b[32mcan significantly extend the model capabilities.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the \u001b[0m\n",
       "\u001b[32mwater. While some other animals can use tools, the complexity is not comparable with humans. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Animals\u001b[0m\n",
       "\u001b[32musing tools\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nMRKL \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKarpas et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic\u001b[0m\n",
       "\u001b[32marchitecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the \u001b[0m\n",
       "\u001b[32mgeneral-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be \u001b[0m\n",
       "\u001b[32mneural \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. deep learning models\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or symbolic \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. math calculator, currency converter, weather API\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test \u001b[0m\n",
       "\u001b[32mcase. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math \u001b[0m\n",
       "\u001b[32mproblems because LLMs \u001b[0m\u001b[32m(\u001b[0m\u001b[32m7B Jurassic1-large model\u001b[0m\u001b[32m)\u001b[0m\u001b[32m failed to extract the right arguments for the basic arithmetic \u001b[0m\n",
       "\u001b[32mreliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use \u001b[0m\n",
       "\u001b[32mthe tools are crucial, determined by the LLM capability.\\nBoth TALM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTool Augmented Language Models; Parisi et al. \u001b[0m\n",
       "\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Toolformer \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchick et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m fine-tune a LM to learn to use external tool APIs. The dataset is \u001b[0m\n",
       "\u001b[32mexpanded based on whether a newly added API call annotation can improve the quality of model outputs. See more \u001b[0m\n",
       "\u001b[32mdetails in the “External APIs” section of Prompt Engineering.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with \u001b[0m\n",
       "\u001b[32mtool use capability working in practice. The collection of tool APIs can be provided by other developers \u001b[0m\u001b[32m(\u001b[0m\u001b[32mas in \u001b[0m\n",
       "\u001b[32mPlugins\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or self-defined \u001b[0m\u001b[32m(\u001b[0m\u001b[32mas in function calls\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nHuggingGPT \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a framework to use ChatGPT as \u001b[0m\n",
       "\u001b[32mthe task planner to select models available in HuggingFace platform according to the model descriptions and \u001b[0m\n",
       "\u001b[32msummarize the response based on the execution results.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 11. Illustration of how HuggingGPT works. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Shen et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThe system \u001b[0m\n",
       "\u001b[32mcomprises of 4 stages:\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task planning: LLM works as the brain and parses the user requests into multiple tasks.\u001b[0m\n",
       "\u001b[32mThere are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot \u001b[0m\n",
       "\u001b[32mexamples to guide LLM to do task parsing and planning.\\nInstruction:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'The AI assistant can parse user input to several tasks: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"task\": task, \"id\", task_id, \"dep\":\u001b[0m\n",
       "\u001b[32mdependency_task_ids, \"args\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. The \"dep\" field denotes \u001b[0m\n",
       "\u001b[32mthe id of the previous task which generates a new resource that the current task relies on. A special tag \u001b[0m\n",
       "\u001b[32m\"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task \u001b[0m\n",
       "\u001b[32mMUST be selected from the following options: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Available Task List \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. There is a logical relationship between \u001b[0m\n",
       "\u001b[32mtasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several \u001b[0m\n",
       "\u001b[32mcases for your reference: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Demonstrations \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. The chat history is recorded as \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Chat History \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. From this chat \u001b[0m\n",
       "\u001b[32mhistory, you can find the path of the user-mentioned resources for your task planning.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Model selection: LLM distributes the tasks to expert models, where the request is framed \u001b[0m\n",
       "\u001b[32mas a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context \u001b[0m\n",
       "\u001b[32mlength, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI \u001b[0m\n",
       "\u001b[32massistant helps the user to select a suitable model from a list of models to process the user request. The AI \u001b[0m\n",
       "\u001b[32massistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \u001b[0m\n",
       "\u001b[32m\"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mCandidate Models \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Please select one model from the list.\\n\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task execution: Expert models execute on the \u001b[0m\n",
       "\u001b[32mspecific tasks and log results.\\nInstruction:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task execution: Expert models execute on the specific tasks and log \u001b[0m\n",
       "\u001b[32mresults.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process \u001b[0m\n",
       "\u001b[32mand results. The previous stages can be formed as - User Input: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m User Input \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Planning: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Tasks \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Model\u001b[0m\n",
       "\u001b[32mSelection: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Model Assignment \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Execution: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Predictions \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. You must first answer the user's request in a\u001b[0m\n",
       "\u001b[32mstraightforward manner. Then describe the task process and show your analysis and model inference results to the \u001b[0m\n",
       "\u001b[32muser in the first person. If inference results contain a file path, must tell the user the complete file path.\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32m4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Response generation: LLM receives the execution results and provides summarized results \u001b[0m\n",
       "\u001b[32mto users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Efficiency improvement \u001b[0m\n",
       "\u001b[32mis needed as both LLM inference rounds and interactions with other models slow down the process; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m It relies on a\u001b[0m\n",
       "\u001b[32mlong context window to communicate over complicated task content; \u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Stability improvement of LLM outputs and \u001b[0m\n",
       "\u001b[32mexternal model services.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'API-Bank \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLi et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a benchmark for evaluating the performance of tool-augmented \u001b[0m\n",
       "\u001b[32mLLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues \u001b[0m\n",
       "\u001b[32mthat involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar \u001b[0m\n",
       "\u001b[32mqueries, smart home control, schedule management, health data management, account authentication workflow and more.\u001b[0m\n",
       "\u001b[32mBecause there are a large number of APIs, LLM first has access to API search engine to find the right API to call \u001b[0m\n",
       "\u001b[32mand then uses the corresponding documentation to make a call.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 12. Pseudo code of how LLM makes an API call in API-Bank. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Li et al. \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how \u001b[0m\n",
       "\u001b[32maccurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if\u001b[0m\n",
       "\u001b[32mnot good enough, LLMs need to iteratively modify the API inputs \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. deciding search keywords for Search Engine \u001b[0m\n",
       "\u001b[32mAPI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nResponse based on the API results: the model can choose to refine and call again if results are not \u001b[0m\n",
       "\u001b[32msatisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'This benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 \u001b[0m\n",
       "\u001b[32mevaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a \u001b[0m\n",
       "\u001b[32mgiven API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the \u001b[0m\n",
       "\u001b[32mAPI. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by\u001b[0m\n",
       "\u001b[32mreading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user \u001b[0m\n",
       "\u001b[32mrequests \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. schedule group meetings, book flight/hotel/restaurant for a trip\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, the model may have to conduct \u001b[0m\n",
       "\u001b[32mmultiple API calls to solve it.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Case Studies#\\nScientific Discovery Agent#\\nChemCrow \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBran et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a domain-specific \u001b[0m\n",
       "\u001b[32mexample in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug \u001b[0m\n",
       "\u001b[32mdiscovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in \u001b[0m\n",
       "\u001b[32mthe ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list\u001b[0m\n",
       "\u001b[32mof tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed \u001b[0m\n",
       "\u001b[32mto answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow\u001b[0m\n",
       "\u001b[32mthe ReAct format - Thought, Action, Action Input, Observation.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and \u001b[0m\n",
       "\u001b[32mChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical \u001b[0m\n",
       "\u001b[32mcorrectness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential \u001b[0m\n",
       "\u001b[32mproblem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of \u001b[0m\n",
       "\u001b[32mexpertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko \u001b[0m\n",
       "\u001b[32met al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, \u001b[0m\n",
       "\u001b[32mplanning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read \u001b[0m\n",
       "\u001b[32mdocumentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when \u001b[0m\n",
       "\u001b[32mrequested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a \u001b[0m\n",
       "\u001b[32mscaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'They also discussed the risks, especially with illicit drugs and bioweapons. They developed a\u001b[0m\n",
       "\u001b[32mtest set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 \u001b[0m\n",
       "\u001b[32mrequests \u001b[0m\u001b[32m(\u001b[0m\u001b[32m36%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m were accepted to obtain a synthesis solution and the agent attempted to consult documentation to \u001b[0m\n",
       "\u001b[32mexecute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search \u001b[0m\n",
       "\u001b[32mwhile 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPark, et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mis super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and \u001b[0m\n",
       "\u001b[32minteracting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human \u001b[0m\n",
       "\u001b[32mbehavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and \u001b[0m\n",
       "\u001b[32mreflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other \u001b[0m\n",
       "\u001b[32magents.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Memory stream: is a long-term memory module \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexternal database\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that records a comprehensive \u001b[0m\n",
       "\u001b[32mlist of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by \u001b[0m\n",
       "\u001b[32mthe agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces\u001b[0m\n",
       "\u001b[32mthe context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent \u001b[0m\n",
       "\u001b[32mevents have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based \u001b[0m\n",
       "\u001b[32mon how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher \u001b[0m\n",
       "\u001b[32mlevel inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32m<\u001b[0m\u001b[32m-\u001b[0m\u001b[32m note that this is a bit different from self-reflection above\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'source'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mpage_content\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Prompt\u001b[0m\u001b[32m LM with 100 most recent observations and to generate 3 most salient high-level \u001b[0m\n",
       "\u001b[32mquestions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: \u001b[0m\n",
       "\u001b[32mtranslate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to \u001b[0m\n",
       "\u001b[32moptimize believability at the moment vs in time.\\nPrompt template: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mIntro of an agent X\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Here is X's plan today in\u001b[0m\n",
       "\u001b[32mbroad strokes: 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nRelationships between agents and observations of one agent by another are all taken into \u001b[0m\n",
       "\u001b[32mconsideration for planning and reacting.\\nEnvironment information is present in a tree structure.\"\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'source'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mpage_content\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Fig. 13. The generative agent architecture. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mImage source: Park et al. 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nThis fun \u001b[0m\n",
       "\u001b[32msimulation results in emergent social behavior, such as information diffusion, relationship memory \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. two agents\u001b[0m\n",
       "\u001b[32mcontinuing the conversation topic\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and coordination of social events \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. host a party and invite many \u001b[0m\n",
       "\u001b[32mothers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up \u001b[0m\n",
       "\u001b[32mautonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural \u001b[0m\n",
       "\u001b[32mlanguage interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format \u001b[0m\n",
       "\u001b[32mparsing.\\nHere is the system message used by AutoGPT, where \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m...\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m are user inputs:\\nYou are \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mai-name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided AI bot description\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\nYour decisions must always be made independently without seeking user \u001b[0m\n",
       "\u001b[32massistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'source'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mpage_content\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'GOALS:\\n\\n1. \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided goal 1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n2. \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser-provided goal 2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n3. ...\\n4. ...\\n5. \u001b[0m\n",
       "\u001b[32m...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately \u001b[0m\n",
       "\u001b[32msave important information to files.\\n2. If you are unsure how you previously did something or want to recall past \u001b[0m\n",
       "\u001b[32mevents, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the \u001b[0m\n",
       "\u001b[32mcommands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate \u001b[0m\n",
       "\u001b[32mwithin a few minutes'\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'source'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mpage_content\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \u001b[0m\n",
       "\u001b[32m\"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \u001b[0m\n",
       "\u001b[32m\"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \u001b[0m\n",
       "\u001b[32m\"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete \u001b[0m\n",
       "\u001b[32mGPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \u001b[0m\n",
       "\u001b[32m\"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \u001b[0m\n",
       "\u001b[32m\"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \u001b[0m\n",
       "\u001b[32m\"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \u001b[0m\n",
       "\u001b[32m\"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \u001b[0m\n",
       "\u001b[32m\"<full_code_string>\"'\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'source'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[33mpage_content\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", \u001b[0m\n",
       "\u001b[32margs: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get \u001b[0m\n",
       "\u001b[32mImproved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. \u001b[0m\n",
       "\u001b[32mWrite Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute \u001b[0m\n",
       "\u001b[32mPython File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \u001b[0m\n",
       "\u001b[32m\"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task \u001b[0m\n",
       "\u001b[32mComplete \u001b[0m\u001b[32m(\u001b[0m\u001b[32mShutdown\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: \"task_complete\", args: \"reason\": \"<reason\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory \u001b[0m\n",
       "\u001b[32mmanagement.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance \u001b[0m\n",
       "\u001b[32mEvaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your \u001b[0m\n",
       "\u001b[32mabilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions \u001b[0m\n",
       "\u001b[32mand strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete \u001b[0m\n",
       "\u001b[32mtasks in the least number of steps.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'You should only respond in JSON format as described below\\nResponse Format:\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \u001b[0m\n",
       "\u001b[32m\"thoughts\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n-\u001b[0m\n",
       "\u001b[32mlist that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \u001b[0m\n",
       "\u001b[32m\"thoughts summary to say to user\"\\n    \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n    \"command\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n        \"name\": \"command name\",\\n        \"args\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \u001b[0m\n",
       "\u001b[32m\"arg name\": \"value\"\\n        \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n    \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is \u001b[0m\n",
       "\u001b[32manother project to create a whole repository of code given a task specified in natural language. The GPT-Engineer \u001b[0m\n",
       "\u001b[32mis instructed to think over a list of smaller components to build and ask for user input to clarify questions as \u001b[0m\n",
       "\u001b[32mneeded.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by \u001b[0m\n",
       "\u001b[32mGPT-Engineer. The user inputs are wrapped in \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser input text\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"system\",'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint \u001b[0m\n",
       "\u001b[32mused by GPT-Engineer. The user inputs are wrapped in \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32muser input text\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"system\",\\n    \u001b[0m\n",
       "\u001b[32m\"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will \u001b[0m\n",
       "\u001b[32mfirst summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying\u001b[0m\n",
       "\u001b[32mquestion, and wait for an answer from the user.\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \"content\": \"We are writing\u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32ma Super Mario game in python. MVC components split in separate files. Keyboard control.\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \u001b[0m\n",
       "\u001b[32m\"role\": \"assistant\",'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \"content\": \"We are writing \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32ma Super Mario game in python. \u001b[0m\n",
       "\u001b[32mMVC components split in separate files. Keyboard control.\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"assistant\",\\n    \u001b[0m\n",
       "\u001b[32m\"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. level design, \u001b[0m\n",
       "\u001b[32mcharacters, gameplay mechanics\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n2. Details about the MVC components \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. which components are in each file\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n3.\u001b[0m\n",
       "\u001b[32mKeyboard control implementation \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. which keys to use, how to handle input\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n\\\\nClarifying question:\\\\nCan you \u001b[0m\n",
       "\u001b[32mprovide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n\u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \"content\": \"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mThere are 10 levels in total. The main \u001b[0m\n",
       "\u001b[32mcharacter is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. \u001b[0m\n",
       "\u001b[32mThe main character moves from left to right, trying to get to the destination, where there are many obstacles and \u001b[0m\n",
       "\u001b[32mattacks from enemies in the process.\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mremaining\u001b[0m\n",
       "\u001b[32munclear areas\u001b[0m\u001b[32m}\u001b[0m\u001b[32m remaining questions.\\\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mNext question\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing\u001b[0m\n",
       "\u001b[32mmore to clarify.\\\\\".\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining \u001b[0m\n",
       "\u001b[32mquestions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",\\n    \"content\": \"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mMake your own assumptions and state them explicitly before starting\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n \u001b[0m\n",
       "\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nThen after these clarification, the agent moved into the code writing mode with a \u001b[0m\n",
       "\u001b[32mdifferent system message.\\nSystem message:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'You will get instructions for code to write.\\nYou will write a very long answer. Make sure \u001b[0m\n",
       "\u001b[32mthat every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the \u001b[0m\n",
       "\u001b[32marchitecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to\u001b[0m\n",
       "\u001b[32mmake sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be \u001b[0m\n",
       "\u001b[32mnecessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including \u001b[0m\n",
       "\u001b[32mALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced\u001b[0m\n",
       "\u001b[32msuch that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block \u001b[0m\n",
       "\u001b[32mlanguage for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file,\u001b[0m\n",
       "\u001b[32mthen go to the ones that are imported by that file, and so on.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'FILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are \u001b[0m\n",
       "\u001b[32mimported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a\u001b[0m\n",
       "\u001b[32mlanguage and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports,\u001b[0m\n",
       "\u001b[32mtypes etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if\u001b[0m\n",
       "\u001b[32myou are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency \u001b[0m\n",
       "\u001b[32mdefinition file.\\nBefore you finish, double check that all parts of the architecture is present in the \u001b[0m\n",
       "\u001b[32mfiles.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create\u001b[0m\n",
       "\u001b[32man appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always \u001b[0m\n",
       "\u001b[32madd a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very \u001b[0m\n",
       "\u001b[32mcomplex bits of logic.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'You always add a comment briefly describing the purpose of the function definition.\\nYou try \u001b[0m\n",
       "\u001b[32mto add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested \u001b[0m\n",
       "\u001b[32mlanguages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'pytest\\ndataclasses'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Conversatin samples:\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"system\",'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer.\u001b[0m\n",
       "\u001b[32mMake sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail \u001b[0m\n",
       "\u001b[32mof the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right \u001b[0m\n",
       "\u001b[32mdecisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods \u001b[0m\n",
       "\u001b[32mthat will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each \u001b[0m\n",
       "\u001b[32mfile including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens \u001b[0m\n",
       "\u001b[32mmust be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup\u001b[0m\n",
       "\u001b[32mcode block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou \u001b[0m\n",
       "\u001b[32mwill start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou\u001b[0m\n",
       "\u001b[32mwill start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease \u001b[0m\n",
       "\u001b[32mnote that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate \u001b[0m\n",
       "\u001b[32mbest practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in\u001b[0m\n",
       "\u001b[32mdifferent files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a \u001b[0m\n",
       "\u001b[32mplausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you \u001b[0m\n",
       "\u001b[32mfinish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost \u001b[0m\n",
       "\u001b[32malways put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt \u001b[0m\n",
       "\u001b[32mfile.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly \u001b[0m\n",
       "\u001b[32mdescribing the purpose of'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always \u001b[0m\n",
       "\u001b[32mcreate an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function \u001b[0m\n",
       "\u001b[32mdefinition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices\u001b[0m\n",
       "\u001b[32mfor the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython \u001b[0m\n",
       "\u001b[32mtoolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them \u001b[0m\n",
       "\u001b[32mexplicitly before starting\".\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model \u001b[0m\n",
       "\u001b[32mwill contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The \u001b[0m\n",
       "\u001b[32mview will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the \u001b[0m\n",
       "\u001b[32mdisplay.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model \u001b[0m\n",
       "\u001b[32maccordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control \u001b[0m\n",
       "\u001b[32mimplementation you would like me to clarify?\"\\n  \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n  \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"role\": \"user\",'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the\u001b[0m\n",
       "\u001b[32mright decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods \u001b[0m\n",
       "\u001b[32mthat will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each \u001b[0m\n",
       "\u001b[32mfile including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens \u001b[0m\n",
       "\u001b[32mmust be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup\u001b[0m\n",
       "\u001b[32mcode block language for the code\\'s language, and CODE is the \u001b[0m\n",
       "\u001b[32mcode:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No \u001b[0m\n",
       "\u001b[32mplaceholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that \u001b[0m\n",
       "\u001b[32mfile, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure \u001b[0m\n",
       "\u001b[32mthat files contain all imports, types etc. The code should be fully'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'are imported by that file, and so on.\\\\nFollow a language and framework appropriate best \u001b[0m\n",
       "\u001b[32mpractice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully \u001b[0m\n",
       "\u001b[32mfunctional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double \u001b[0m\n",
       "\u001b[32mcheck that all parts of the architecture is present in the files.\\\\n\"'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I\u001b[0m\n",
       "\u001b[32mstart to see a couple common limitations:'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Finite context length: The restricted context capacity limits the inclusion of historical \u001b[0m\n",
       "\u001b[32minformation, detailed instructions, API call context, and responses. The design of the system has to work with this\u001b[0m\n",
       "\u001b[32mlimited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a \u001b[0m\n",
       "\u001b[32mlot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger \u001b[0m\n",
       "\u001b[32mknowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term \u001b[0m\n",
       "\u001b[32mplanning and task decomposition: Planning over a lengthy history and effectively exploring the solution space \u001b[0m\n",
       "\u001b[32mremain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust \u001b[0m\n",
       "\u001b[32mcompared to humans who learn from trial and error.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Reliability of natural language interface: Current agent system relies on natural language as\u001b[0m\n",
       "\u001b[32man interface between LLMs and external components such as memory and tools. However, the reliability of model \u001b[0m\n",
       "\u001b[32moutputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. \u001b[0m\n",
       "\u001b[32mrefuse to follow an instruction\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consequently, much of the agent demo code focuses on parsing model \u001b[0m\n",
       "\u001b[32moutput.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJun 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. “LLM-powered Autonomous Agents”. Lil’Log. \u001b[0m\n",
       "\u001b[32mhttps://lilianweng.github.io/posts/2023-06-23-agent/.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Or\\n@article\u001b[0m\u001b[32m{\u001b[0m\u001b[32mweng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng,\u001b[0m\n",
       "\u001b[32mLilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \u001b[0m\n",
       "\u001b[32m\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nReferences#\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Wei et al. “Chain of thought prompting \u001b[0m\n",
       "\u001b[32melicits reasoning in large language models.” NeurIPS 2022\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. “Tree of Thoughts: Dliberate Problem \u001b[0m\n",
       "\u001b[32mSolving with Large Language Models.” arXiv preprint arXiv:2305.10601 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m3\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. “Chain of Hindsight \u001b[0m\n",
       "\u001b[32mAligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Liu et al. “LLM+P: Empowering \u001b[0m\n",
       "\u001b[32mLarge Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Yao et al. \u001b[0m\n",
       "\u001b[32m“ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Google Blog. “Announcing ScaNN: \u001b[0m\n",
       "\u001b[32mEfficient Vector Similarity Search” July 28, 2020.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mhttps://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mhttps://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m8\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Shinn & Labash. “Reflexion: an autonomous \u001b[0m\n",
       "\u001b[32magent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Laskin et al. \u001b[0m\n",
       "\u001b[32m“In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m10\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Karpas et al. “MRKL Systems A \u001b[0m\n",
       "\u001b[32mmodular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete \u001b[0m\n",
       "\u001b[32mreasoning.” arXiv preprint arXiv:2205.00445 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Nakano et al. “Webgpt: Browser-assisted \u001b[0m\n",
       "\u001b[32mquestion-answering with human feedback.” arXiv preprint arXiv:2112.09332 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Parisi et al. “TALM: Tool \u001b[0m\n",
       "\u001b[32mAugmented Language Models”\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” \u001b[0m\n",
       "\u001b[32marXiv preprint arXiv:2302.04761 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv \u001b[0m\n",
       "\u001b[32mpreprint arXiv:2302.04761 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m14\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m15\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Li et al. \u001b[0m\n",
       "\u001b[32m“API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m16\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Shen et al. \u001b[0m\n",
       "\u001b[32m“HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m17\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint \u001b[0m\n",
       "\u001b[32marXiv:2304.05376 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m18\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Boiko et al. “Emergent autonomous scientific research capabilities of large language\u001b[0m\n",
       "\u001b[32mmodels.” arXiv preprint arXiv:2304.05332 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m19\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Joon Sung Park, et al. “Generative Agents: Interactive \u001b[0m\n",
       "\u001b[32mSimulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m20\u001b[0m\u001b[32m]\u001b[0m\u001b[32m AutoGPT. \u001b[0m\n",
       "\u001b[32mhttps://github.com/Significant-Gravitas/Auto-GPT\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m21\u001b[0m\u001b[32m]\u001b[0m\u001b[32m GPT-Engineer. https://github.com/AntonOsika/gpt-engineer'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryVectorStore\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m vector_store = InMemoryVectorStore(\u001b[43membeddings\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Index chunks\u001b[39;00m\n\u001b[32m      5\u001b[39m _ = vector_store.add_documents(documents=all_splits)\n",
      "\u001b[31mNameError\u001b[39m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
